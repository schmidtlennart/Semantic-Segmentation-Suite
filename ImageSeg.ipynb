{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.2.0.32-cp36-cp36m-manylinux1_x86_64.whl (28.2 MB)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /gpfs/software/juwels/stages/Devel-2019a/software/SciPy-Stack/2019a-gcccoremkl-8.3.0-2019.3.199-Python-3.6.8/lib/python3.6/site-packages/numpy-1.15.2-py3.6-linux-x86_64.egg (from opencv-python) (1.15.2)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.2.0.32\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --prefix \"/p/home/jusers/schmidt9/juwels/PROJECT_testufz/Custompip\" opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"/p/home/jusers/schmidt9/juwels/PROJECT_testufz/Custompip/lib/python3.6/site-packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Preparing the model ...\\nThis model has 1366211 trainable parameters\\nLoading the data ...\\n\\n***** Begin training *****\\nDataset --> data/\\nModel --> FC-DenseNet56\\nCrop Height --> 512\\nCrop Width --> 512\\nNum Epochs --> 2\\nBatch Size --> 2\\nNum Classes --> 11\\nData Augmentation:\\n\\tVertical Flip --> False\\n\\tHorizontal Flip --> False\\n\\tBrightness Alteration --> None\\n\\tRotation --> None\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "from subprocess import PIPE\n",
    "subprocess.run(\"python3 train.py --num_epochs 2 --checkpoint_step 1 --validation_step 1 --dataset data/ --batch_size 2 --num_val_images 10\",shell=True,stdout=PIPE, stderr=PIPE,check=False).stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Preparing the model ...\\n'b'This model has 1366211 trainable parameters\\n'b'Loading the data ...\\n'b'\\n'b'***** Begin training *****\\n'b'Dataset --> data/\\n'b'Model --> FC-DenseNet56\\n'b'Crop Height --> 512\\n'b'Crop Width --> 512\\n'b'Num Epochs --> 2\\n'b'Batch Size --> 2\\n'b'Num Classes --> 11\\n'b'Data Augmentation:\\n'b'\\tVertical Flip --> False\\n'b'\\tHorizontal Flip --> False\\n'b'\\tBrightness Alteration --> None\\n'b'\\tRotation --> None\\n'b'\\n'"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from subprocess import PIPE\n",
    "\n",
    "def execute(cmd):\n",
    "    popen = subprocess.Popen(\"python3 train.py --num_epochs 2 --checkpoint_step 1 --validation_step 1 --dataset data/ --batch_size 2 --num_val_images 10\",shell=True,stdout=PIPE, stderr=PIPE)#encoding='utf-8'\n",
    "    for stdout_line in iter(popen.stdout.readline, \"\"):\n",
    "        #return stdout_line.strip().decode().splitlines()\n",
    "        yield stdout_line        \n",
    "    popen.stdout.close()\n",
    "    return_code = popen.wait()\n",
    "    if return_code:\n",
    "        raise subprocess.CalledProcessError(return_code, cmd)\n",
    "\n",
    "for path in execute([\"locate\", \"a\"]):\n",
    "    print(path, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/software/juwels/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/gpfs/software/juwels/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/gpfs/software/juwels/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/gpfs/software/juwels/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/gpfs/software/juwels/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/gpfs/software/juwels/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2fad7ae32ffa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m# Get the names of the classes so we can record the evaluation results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mclass_names_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"class_dict.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0mclass_names_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclass_names_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os,time,cv2, sys, math\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np\n",
    "import time, datetime\n",
    "import argparse\n",
    "import random\n",
    "import os, sys\n",
    "import subprocess\n",
    "\n",
    "# use 'Agg' on matplotlib so that plots could be generated even without Xserver\n",
    "# running\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "from utils import utils, helpers\n",
    "from builders import model_builder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def str2bool(v):\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--num_epochs', type=int, default=300, help='Number of epochs to train for')\n",
    "parser.add_argument('--epoch_start_i', type=int, default=0, help='Start counting epochs from this number')\n",
    "parser.add_argument('--checkpoint_step', type=int, default=5, help='How often to save checkpoints (epochs)')\n",
    "parser.add_argument('--validation_step', type=int, default=1, help='How often to perform validation (epochs)')\n",
    "parser.add_argument('--image', type=str, default=None, help='The image you want to predict on. Only valid in \"predict\" mode.')\n",
    "parser.add_argument('--continue_training', type=str2bool, default=False, help='Whether to continue training from a checkpoint')\n",
    "parser.add_argument('--dataset', type=str, default=\"CamVid\", help='Dataset you are using.')\n",
    "parser.add_argument('--crop_height', type=int, default=512, help='Height of cropped input image to network')\n",
    "parser.add_argument('--crop_width', type=int, default=512, help='Width of cropped input image to network')\n",
    "parser.add_argument('--batch_size', type=int, default=1, help='Number of images in each batch')\n",
    "parser.add_argument('--num_val_images', type=int, default=20, help='The number of images to used for validations')\n",
    "parser.add_argument('--h_flip', type=str2bool, default=False, help='Whether to randomly flip the image horizontally for data augmentation')\n",
    "parser.add_argument('--v_flip', type=str2bool, default=False, help='Whether to randomly flip the image vertically for data augmentation')\n",
    "parser.add_argument('--brightness', type=float, default=None, help='Whether to randomly change the image brightness for data augmentation. Specifies the max bightness change as a factor between 0.0 and 1.0. For example, 0.1 represents a max brightness change of 10%% (+-).')\n",
    "parser.add_argument('--rotation', type=float, default=None, help='Whether to randomly rotate the image for data augmentation. Specifies the max rotation angle in degrees.')\n",
    "parser.add_argument('--model', type=str, default=\"FC-DenseNet56\", help='The model you are using. See model_builder.py for supported models')\n",
    "parser.add_argument('--frontend', type=str, default=\"ResNet101\", help='The frontend you are using. See frontend_builder.py for supported models')\n",
    "#args = parser.parse_args()\n",
    "\n",
    "parser.num_epochs = 2\n",
    "parser.dataset = \"data/\"\n",
    "parser.checkpoint_step=1 \n",
    "parser.validation_step=1\n",
    "parser.batch_size=2\n",
    "parser.num_val_images=10\n",
    "\n",
    "def data_augmentation(input_image, output_image):\n",
    "    # Data augmentation\n",
    "    input_image, output_image = utils.random_crop(input_image, output_image, args.crop_height, args.crop_width)\n",
    "\n",
    "    if args.h_flip and random.randint(0,1):\n",
    "        input_image = cv2.flip(input_image, 1)\n",
    "        output_image = cv2.flip(output_image, 1)\n",
    "    if args.v_flip and random.randint(0,1):\n",
    "        input_image = cv2.flip(input_image, 0)\n",
    "        output_image = cv2.flip(output_image, 0)\n",
    "    if args.brightness:\n",
    "        factor = 1.0 + random.uniform(-1.0*args.brightness, args.brightness)\n",
    "        table = np.array([((i / 255.0) * factor) * 255 for i in np.arange(0, 256)]).astype(np.uint8)\n",
    "        input_image = cv2.LUT(input_image, table)\n",
    "    if args.rotation:\n",
    "        angle = random.uniform(-1*args.rotation, args.rotation)\n",
    "    if args.rotation:\n",
    "        M = cv2.getRotationMatrix2D((input_image.shape[1]//2, input_image.shape[0]//2), angle, 1.0)\n",
    "        input_image = cv2.warpAffine(input_image, M, (input_image.shape[1], input_image.shape[0]), flags=cv2.INTER_NEAREST)\n",
    "        output_image = cv2.warpAffine(output_image, M, (output_image.shape[1], output_image.shape[0]), flags=cv2.INTER_NEAREST)\n",
    "\n",
    "    return input_image, output_image\n",
    "\n",
    "\n",
    "# Get the names of the classes so we can record the evaluation results\n",
    "class_names_list, label_values = helpers.get_label_info(os.path.join(args.dataset, \"class_dict.csv\"))\n",
    "class_names_string = \"\"\n",
    "for class_name in class_names_list:\n",
    "    if not class_name == class_names_list[-1]:\n",
    "        class_names_string = class_names_string + class_name + \", \"\n",
    "    else:\n",
    "        class_names_string = class_names_string + class_name\n",
    "\n",
    "num_classes = len(label_values)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess=tf.Session(config=config)\n",
    "\n",
    "\n",
    "# Compute your softmax cross entropy loss\n",
    "net_input = tf.placeholder(tf.float32,shape=[None,None,None,3])\n",
    "net_output = tf.placeholder(tf.float32,shape=[None,None,None,num_classes])\n",
    "\n",
    "network, init_fn = model_builder.build_model(model_name=args.model, frontend=args.frontend, net_input=net_input, num_classes=num_classes, crop_width=args.crop_width, crop_height=args.crop_height, is_training=True)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=network, labels=net_output))\n",
    "\n",
    "opt = tf.train.RMSPropOptimizer(learning_rate=0.0001, decay=0.995).minimize(loss, var_list=[var for var in tf.trainable_variables()])\n",
    "\n",
    "saver=tf.train.Saver(max_to_keep=1000)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "utils.count_params()\n",
    "\n",
    "# If a pre-trained ResNet is required, load the weights.\n",
    "# This must be done AFTER the variables are initialized with sess.run(tf.global_variables_initializer())\n",
    "if init_fn is not None:\n",
    "    init_fn(sess)\n",
    "\n",
    "# Load a previous checkpoint if desired\n",
    "model_checkpoint_name = \"checkpoints/latest_model_\" + args.model + \"_\" + args.dataset + \".ckpt\"\n",
    "if args.continue_training:\n",
    "    print('Loaded latest model checkpoint')\n",
    "    saver.restore(sess, model_checkpoint_name)\n",
    "\n",
    "# Load the data\n",
    "print(\"Loading the data ...\")\n",
    "train_input_names,train_output_names, val_input_names, val_output_names, test_input_names, test_output_names = utils.prepare_data(dataset_dir=args.dataset)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n***** Begin training *****\")\n",
    "print(\"Dataset -->\", args.dataset)\n",
    "print(\"Model -->\", args.model)\n",
    "print(\"Crop Height -->\", args.crop_height)\n",
    "print(\"Crop Width -->\", args.crop_width)\n",
    "print(\"Num Epochs -->\", args.num_epochs)\n",
    "print(\"Batch Size -->\", args.batch_size)\n",
    "print(\"Num Classes -->\", num_classes)\n",
    "\n",
    "print(\"Data Augmentation:\")\n",
    "print(\"\\tVertical Flip -->\", args.v_flip)\n",
    "print(\"\\tHorizontal Flip -->\", args.h_flip)\n",
    "print(\"\\tBrightness Alteration -->\", args.brightness)\n",
    "print(\"\\tRotation -->\", args.rotation)\n",
    "print(\"\")\n",
    "\n",
    "avg_loss_per_epoch = []\n",
    "avg_scores_per_epoch = []\n",
    "avg_iou_per_epoch = []\n",
    "\n",
    "# Which validation images do we want\n",
    "val_indices = []\n",
    "num_vals = min(args.num_val_images, len(val_input_names))\n",
    "\n",
    "# Set random seed to make sure models are validated on the same validation images.\n",
    "# So you can compare the results of different models more intuitively.\n",
    "random.seed(16)\n",
    "val_indices=random.sample(range(0,len(val_input_names)),num_vals)\n",
    "\n",
    "# Do the training here\n",
    "for epoch in range(args.epoch_start_i, args.num_epochs):\n",
    "\n",
    "    current_losses = []\n",
    "\n",
    "    cnt=0\n",
    "\n",
    "    # Equivalent to shuffling\n",
    "    id_list = np.random.permutation(len(train_input_names))\n",
    "\n",
    "    num_iters = int(np.floor(len(id_list) / args.batch_size))\n",
    "    st = time.time()\n",
    "    epoch_st=time.time()\n",
    "    for i in range(num_iters):\n",
    "        # st=time.time()\n",
    "\n",
    "        input_image_batch = []\n",
    "        output_image_batch = []\n",
    "\n",
    "        # Collect a batch of images\n",
    "        for j in range(args.batch_size):\n",
    "            index = i*args.batch_size + j\n",
    "            id = id_list[index]\n",
    "            input_image = utils.load_image(train_input_names[id])\n",
    "            output_image = utils.load_image(train_output_names[id])\n",
    "\n",
    "            with tf.device('/cpu:0'):\n",
    "                input_image, output_image = data_augmentation(input_image, output_image)\n",
    "\n",
    "\n",
    "                # Prep the data. Make sure the labels are in one-hot format\n",
    "                input_image = np.float32(input_image) / 255.0\n",
    "                output_image = np.float32(helpers.one_hot_it(label=output_image, label_values=label_values))\n",
    "\n",
    "                input_image_batch.append(np.expand_dims(input_image, axis=0))\n",
    "                output_image_batch.append(np.expand_dims(output_image, axis=0))\n",
    "\n",
    "        if args.batch_size == 1:\n",
    "            input_image_batch = input_image_batch[0]\n",
    "            output_image_batch = output_image_batch[0]\n",
    "        else:\n",
    "            input_image_batch = np.squeeze(np.stack(input_image_batch, axis=1))\n",
    "            output_image_batch = np.squeeze(np.stack(output_image_batch, axis=1))\n",
    "\n",
    "        # Do the training\n",
    "        _,current=sess.run([opt,loss],feed_dict={net_input:input_image_batch,net_output:output_image_batch})\n",
    "        current_losses.append(current)\n",
    "        cnt = cnt + args.batch_size\n",
    "        if cnt % 20 == 0:\n",
    "            string_print = \"Epoch = %d Count = %d Current_Loss = %.4f Time = %.2f\"%(epoch,cnt,current,time.time()-st)\n",
    "            utils.LOG(string_print)\n",
    "            st = time.time()\n",
    "\n",
    "    mean_loss = np.mean(current_losses)\n",
    "    avg_loss_per_epoch.append(mean_loss)\n",
    "\n",
    "    # Create directories if needed\n",
    "    if not os.path.isdir(\"%s/%04d\"%(\"checkpoints\",epoch)):\n",
    "        os.makedirs(\"%s/%04d\"%(\"checkpoints\",epoch))\n",
    "\n",
    "    # Save latest checkpoint to same file name\n",
    "    print(\"Saving latest checkpoint\")\n",
    "    saver.save(sess,model_checkpoint_name)\n",
    "\n",
    "    if val_indices != 0 and epoch % args.checkpoint_step == 0:\n",
    "        print(\"Saving checkpoint for this epoch\")\n",
    "        saver.save(sess,\"%s/%04d/model.ckpt\"%(\"checkpoints\",epoch))\n",
    "\n",
    "\n",
    "    if epoch % args.validation_step == 0:\n",
    "        print(\"Performing validation\")\n",
    "        target=open(\"%s/%04d/val_scores.csv\"%(\"checkpoints\",epoch),'w')\n",
    "        target.write(\"val_name, avg_accuracy, precision, recall, f1 score, mean iou, %s\\n\" % (class_names_string))\n",
    "\n",
    "\n",
    "        scores_list = []\n",
    "        class_scores_list = []\n",
    "        precision_list = []\n",
    "        recall_list = []\n",
    "        f1_list = []\n",
    "        iou_list = []\n",
    "\n",
    "\n",
    "        # Do the validation on a small set of validation images\n",
    "        for ind in val_indices:\n",
    "\n",
    "            input_image = np.expand_dims(np.float32(utils.load_image(val_input_names[ind])[:args.crop_height, :args.crop_width]),axis=0)/255.0\n",
    "            gt = utils.load_image(val_output_names[ind])[:args.crop_height, :args.crop_width]\n",
    "            gt = helpers.reverse_one_hot(helpers.one_hot_it(gt, label_values))\n",
    "\n",
    "            # st = time.time()\n",
    "\n",
    "            output_image = sess.run(network,feed_dict={net_input:input_image})\n",
    "\n",
    "\n",
    "            output_image = np.array(output_image[0,:,:,:])\n",
    "            output_image = helpers.reverse_one_hot(output_image)\n",
    "            out_vis_image = helpers.colour_code_segmentation(output_image, label_values)\n",
    "\n",
    "            accuracy, class_accuracies, prec, rec, f1, iou = utils.evaluate_segmentation(pred=output_image, label=gt, num_classes=num_classes)\n",
    "\n",
    "            file_name = utils.filepath_to_name(val_input_names[ind])\n",
    "            target.write(\"%s, %f, %f, %f, %f, %f\"%(file_name, accuracy, prec, rec, f1, iou))\n",
    "            for item in class_accuracies:\n",
    "                target.write(\", %f\"%(item))\n",
    "            target.write(\"\\n\")\n",
    "\n",
    "            scores_list.append(accuracy)\n",
    "            class_scores_list.append(class_accuracies)\n",
    "            precision_list.append(prec)\n",
    "            recall_list.append(rec)\n",
    "            f1_list.append(f1)\n",
    "            iou_list.append(iou)\n",
    "\n",
    "            gt = helpers.colour_code_segmentation(gt, label_values)\n",
    "\n",
    "            file_name = os.path.basename(val_input_names[ind])\n",
    "            file_name = os.path.splitext(file_name)[0]\n",
    "            cv2.imwrite(\"%s/%04d/%s_pred.png\"%(\"checkpoints\",epoch, file_name),cv2.cvtColor(np.uint8(out_vis_image), cv2.COLOR_RGB2BGR))\n",
    "            cv2.imwrite(\"%s/%04d/%s_gt.png\"%(\"checkpoints\",epoch, file_name),cv2.cvtColor(np.uint8(gt), cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "        target.close()\n",
    "\n",
    "        avg_score = np.mean(scores_list)\n",
    "        class_avg_scores = np.mean(class_scores_list, axis=0)\n",
    "        avg_scores_per_epoch.append(avg_score)\n",
    "        avg_precision = np.mean(precision_list)\n",
    "        avg_recall = np.mean(recall_list)\n",
    "        avg_f1 = np.mean(f1_list)\n",
    "        avg_iou = np.mean(iou_list)\n",
    "        avg_iou_per_epoch.append(avg_iou)\n",
    "\n",
    "        print(\"\\nAverage validation accuracy for epoch # %04d = %f\"% (epoch, avg_score))\n",
    "        print(\"Average per class validation accuracies for epoch # %04d:\"% (epoch))\n",
    "        for index, item in enumerate(class_avg_scores):\n",
    "            print(\"%s = %f\" % (class_names_list[index], item))\n",
    "        print(\"Validation precision = \", avg_precision)\n",
    "        print(\"Validation recall = \", avg_recall)\n",
    "        print(\"Validation F1 score = \", avg_f1)\n",
    "        print(\"Validation IoU score = \", avg_iou)\n",
    "\n",
    "    epoch_time=time.time()-epoch_st\n",
    "    remain_time=epoch_time*(args.num_epochs-1-epoch)\n",
    "    m, s = divmod(remain_time, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    if s!=0:\n",
    "        train_time=\"Remaining training time = %d hours %d minutes %d seconds\\n\"%(h,m,s)\n",
    "    else:\n",
    "        train_time=\"Remaining training time : Training completed.\\n\"\n",
    "    utils.LOG(train_time)\n",
    "    scores_list = []\n",
    "\n",
    "\n",
    "    fig1, ax1 = plt.subplots(figsize=(11, 8))\n",
    "\n",
    "    ax1.plot(range(epoch+1), avg_scores_per_epoch)\n",
    "    ax1.set_title(\"Average validation accuracy vs epochs\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Avg. val. accuracy\")\n",
    "\n",
    "\n",
    "    plt.savefig('accuracy_vs_epochs.png')\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    fig2, ax2 = plt.subplots(figsize=(11, 8))\n",
    "\n",
    "    ax2.plot(range(epoch+1), avg_loss_per_epoch)\n",
    "    ax2.set_title(\"Average loss vs epochs\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Current loss\")\n",
    "\n",
    "    plt.savefig('loss_vs_epochs.png')\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    fig3, ax3 = plt.subplots(figsize=(11, 8))\n",
    "\n",
    "    ax3.plot(range(epoch+1), avg_iou_per_epoch)\n",
    "    ax3.set_title(\"Average IoU vs epochs\")\n",
    "    ax3.set_xlabel(\"Epoch\")\n",
    "    ax3.set_ylabel(\"Current IoU\")\n",
    "\n",
    "    plt.savefig('iou_vs_epochs.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform class labels from json to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "with open(\"data/obj_class_to_machine_color.json\", 'r') as f:\n",
    "    table = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(table.items())#, columns=['Date', 'DateValue']\n",
    "df = pd.concat([df[0],df[1].apply(pd.Series)],axis=1)\n",
    "df.columns = [\"name\",\"r\",\"g\",\"b\"]\n",
    "df.to_csv(\"data/class_dict.csv\",index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datathon_kernel_cpu",
   "language": "python",
   "name": "datathon_kernel_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
