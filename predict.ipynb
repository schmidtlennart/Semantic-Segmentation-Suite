{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"/p/home/jusers/schmidt9/juwels/PROJECT_testufz/Custompip/lib/python3.6/site-packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/software/juwels/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/gpfs/software/juwels/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/gpfs/software/juwels/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/gpfs/software/juwels/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/gpfs/software/juwels/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/gpfs/software/juwels/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Begin prediction *****\n",
      "Dataset --> data\n",
      "Model --> MobileUNet\n",
      "Crop Height --> 512\n",
      "Crop Width --> 512\n",
      "Num Classes --> 11\n",
      "Preparing the model ...\n",
      "WARNING:tensorflow:From /gpfs/software/juwels/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading model checkpoint weights\n",
      "WARNING:tensorflow:From /gpfs/software/juwels/stages/Devel-2019a/software/TensorFlow/1.13.1-GCCcore-8.3.0-GPU-Python-3.6.8/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/latest_model_MobileUNet_data.ckpt\n",
      "Testing image data/test/2019_0821_145356_115.jpg\n",
      "\n",
      "Finished!\n",
      "Wrote image 2019_0821_145356_115_pred.png\n",
      "Testing image data/test/2019_0821_145456_118.jpg\n",
      "\n",
      "Finished!\n",
      "Wrote image 2019_0821_145456_118_pred.png\n",
      "Testing image data/test/2019_0821_145658_124.jpg\n",
      "\n",
      "Finished!\n",
      "Wrote image 2019_0821_145658_124_pred.png\n",
      "Testing image data/test/2019_0821_145718_125.jpg\n",
      "\n",
      "Finished!\n",
      "Wrote image 2019_0821_145718_125_pred.png\n",
      "Testing image data/test/2019_0821_145335_114.jpg\n",
      "\n",
      "Finished!\n",
      "Wrote image 2019_0821_145335_114_pred.png\n",
      "Testing image data/test/2019_0821_145557_121.jpg\n",
      "\n",
      "Finished!\n",
      "Wrote image 2019_0821_145557_121_pred.png\n",
      "Testing image data/test/2019_0821_145819_128.jpg\n",
      "\n",
      "Finished!\n",
      "Wrote image 2019_0821_145819_128_pred.png\n",
      "Testing image data/test/2019_0821_145436_117.jpg\n",
      "\n",
      "Finished!\n",
      "Wrote image 2019_0821_145436_117_pred.png\n",
      "Testing image data/test/2019_0821_145416_116.jpg\n",
      "\n",
      "Finished!\n",
      "Wrote image 2019_0821_145416_116_pred.png\n",
      "Testing image data/test/2019_0821_145537_120.jpg\n",
      "\n",
      "Finished!\n",
      "Wrote image 2019_0821_145537_120_pred.png\n",
      "Testing image data/test/2019_0821_145839_129.jpg\n",
      "\n",
      "Finished!\n",
      "Wrote image 2019_0821_145839_129_pred.png\n",
      "Testing image data/test/2019_0821_145739_126.jpg\n",
      "\n",
      "Finished!\n",
      "Wrote image 2019_0821_145739_126_pred.png\n",
      "Testing image data/test/2019_0821_145517_119.jpg\n",
      "\n",
      "Finished!\n",
      "Wrote image 2019_0821_145517_119_pred.png\n",
      "Testing image data/test/2019_0821_145617_122.jpg\n",
      "\n",
      "Finished!\n",
      "Wrote image 2019_0821_145617_122_pred.png\n",
      "Testing image data/test/2019_0821_145638_123.jpg\n",
      "\n",
      "Finished!\n",
      "Wrote image 2019_0821_145638_123_pred.png\n",
      "Testing image data/test/2019_0821_145759_127.jpg\n",
      "\n",
      "Finished!\n",
      "Wrote image 2019_0821_145759_127_pred.png\n"
     ]
    }
   ],
   "source": [
    "import os,time,cv2, sys, math\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from utils import utils, helpers\n",
    "from builders import model_builder\n",
    "\n",
    "dataset= \"data\" #dataset-folder, default:\"CamVid\"\n",
    "crop_height=512 #Height of cropped input image to network\n",
    "crop_width=512 #Width of cropped input image to network\n",
    "#model=\"Encoder-Decoder\" #The model you are using. See model_builder.py for supported models,\"FC-DenseNet56\"\n",
    "model=\"MobileUNet\"\n",
    "checkpoint_path=\"checkpoints/latest_model_\" +  model + \"_\" +  dataset + \".ckpt\"\n",
    "#image = \"data/test/2019_0821_145335_114.jpg\"\n",
    "imagefolder=\"data/test\"\n",
    "images=[]\n",
    "import os\n",
    "for file in os.listdir(imagefolder):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        images.append(os.path.join(imagefolder, file))\n",
    "\n",
    "class_names_list, label_values = helpers.get_label_info(os.path.join( dataset, \"class_dict.csv\"))\n",
    "\n",
    "num_classes = len(label_values)\n",
    "\n",
    "print(\"\\n***** Begin prediction *****\")\n",
    "print(\"Dataset -->\",  dataset)\n",
    "print(\"Model -->\",  model)\n",
    "print(\"Crop Height -->\",  crop_height)\n",
    "print(\"Crop Width -->\",  crop_width)\n",
    "print(\"Num Classes -->\", num_classes)\n",
    "#print(\"Image -->\",  image)\n",
    "tf.reset_default_graph()#delete previous variables (?)\n",
    "\n",
    "# Initializing network\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess=tf.Session(config=config)\n",
    "\n",
    "net_input = tf.placeholder(tf.float32,shape=[None,None,None,3])\n",
    "net_output = tf.placeholder(tf.float32,shape=[None,None,None,num_classes]) \n",
    "\n",
    "network, _ = model_builder.build_model( model, net_input=net_input,\n",
    "                                        num_classes=num_classes,\n",
    "                                        crop_width= crop_width,\n",
    "                                        crop_height= crop_height,\n",
    "                                        is_training=False)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Loading model checkpoint weights')\n",
    "saver=tf.train.Saver(max_to_keep=1000)\n",
    "saver.restore(sess,  checkpoint_path)\n",
    "\n",
    "for image in images:\n",
    "    print(\"Testing image \" +  image)\n",
    "\n",
    "    loaded_image = utils.load_image(image)\n",
    "    resized_image =cv2.resize(loaded_image, ( crop_width,  crop_height))\n",
    "    input_image = np.expand_dims(np.float32(resized_image[: crop_height, : crop_width]),axis=0)/255.0\n",
    "\n",
    "    st = time.time()\n",
    "    output_image = sess.run(network,feed_dict={net_input:input_image})\n",
    "\n",
    "    run_time = time.time()-st\n",
    "\n",
    "    output_image = np.array(output_image[0,:,:,:])\n",
    "    output_image = helpers.reverse_one_hot(output_image)\n",
    "\n",
    "    out_vis_image = helpers.colour_code_segmentation(output_image, label_values)\n",
    "    out_vis_image[:,:,0] = out_vis_image[:,:,0]*20\n",
    "    out_vis_image[:,:,1] = out_vis_image[:,:,1]*10\n",
    "    out_vis_image[:,:,2] = out_vis_image[:,:,2]*5\n",
    "    # overlay input+predictions\n",
    "    out_both = cv2.addWeighted(resized_image, 0.5, out_vis_image, 0.5, 0.0,dtype=64)\n",
    "    file_name = utils.filepath_to_name(image)\n",
    "    cv2.imwrite(\"%s_pred.png\"%(file_name),cv2.cvtColor(np.uint8(out_both), cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Finished!\")\n",
    "    print(\"Wrote image \" + \"%s_pred.png\"%(file_name))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(out_vis_image.\n",
    "    dtype)\n",
    "print(resized_image.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datathon_kernel",
   "language": "python",
   "name": "datathon_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
